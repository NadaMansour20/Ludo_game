{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LudoEnv:\n",
    "    def __init__(self):\n",
    "        self.goal = 10\n",
    "        self.num_players = 2\n",
    "        self.pieces_per_player = 4\n",
    "        self.state = [[0] * self.pieces_per_player for _ in range(self.num_players)] # 2D list representing player`s pieces positions\n",
    "        self.current_player = 0  # The current player who is taking the turn (0 or 1)\n",
    "        self.done = False  # Game over flag \n",
    "        self.safe_spots = [5, 15, 25, 35, 45]  # List of safe spots where players can rest their pieces (not affected by other players)\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = [[0] * self.pieces_per_player for _ in range(self.num_players)] # Reset the state for a new game, all pieces are at the starting position\n",
    "        self.current_player = 0\n",
    "        self.done = False\n",
    "        return self.get_state()\n",
    "\n",
    "    def get_state(self):\n",
    "        # Return the current state of the game(including each player's pieces positions & current player)\n",
    "        return tuple(tuple(player) for player in self.state), self.current_player\n",
    "    \n",
    "    def get_valid_actions(self):\n",
    "                # ترجع القطع التي يمكن تحريكها (أي التي لم تصل للهدف بعد)\n",
    "        return [i for i, pos in enumerate(self.state[self.current_player]) if pos < self.goal]\n",
    "\n",
    "    def move_piece(self, player, piece_index, steps):\n",
    "                # تحريك قطعة اللاعب بمقدار خطوات معينة\n",
    "        piece_position = self.state[player][piece_index] #الموضع الحالي للقطعة\n",
    "        new_position = piece_position + steps # الموضع الجديد بعد التحريك\n",
    "        \n",
    "        # تحقق من الأكل\n",
    "        opponent = 1 if player == 0 else 0 # تحديد اللاعب المنافس \n",
    "                # التحقق مما إذا تم ضرب قطعة للخصم في مكان غير آمن\n",
    "        for i in range(self.pieces_per_player):\n",
    "            if self.state[opponent][i] == new_position:\n",
    "                self.state[opponent][i] = 0  # إرجاع قطعة الخصم للبداية\n",
    "                return 20, -5  # زيادة المكافأة + عقوبة أقل للخصم\n",
    "\n",
    "        # تحقق من الخانات الآمنة\n",
    "        if new_position in self.safe_spots:\n",
    "            return 5, 0  # مكافأة صغيرة للوصول إلى خانة آمنة\n",
    "\n",
    "        if new_position == self.goal:  # إذا وصلت إلى الهدف\n",
    "            return 20, 0  # زيادة المكافأة\n",
    "\n",
    "        return 0, 0\n",
    "\n",
    "    def step(self, action):\n",
    "        dice_roll = random.randint(1, 6)\n",
    "        reward = 0\n",
    "        player_pieces = self.state[self.current_player]\n",
    "        \n",
    "        # تحريك القطعة\n",
    "        if player_pieces[action] < self.goal:\n",
    "                        # إذا كانت القطعة لم تصل للنهاية فقم بتحريكها\n",
    "            reward, penalty = self.move_piece(self.current_player, action, dice_roll)\n",
    "            player_pieces[action] = min(self.goal, player_pieces[action] + dice_roll)\n",
    "\n",
    "        # إذا تم أكل قطعة، إضافة العقوبة\n",
    "        reward -= penalty\n",
    "\n",
    "        # إذا كانت جميع القطع وصلت\n",
    "        if all(p == self.goal for p in player_pieces):#التحقق إذا فاز اللاعب\n",
    "            reward += 50\n",
    "            self.done = True\n",
    "\n",
    "        # تغيير الدور\n",
    "        self.current_player = 1 - self.current_player #تبديل الدور للاعب الآخر\n",
    "\n",
    "        return self.get_state(), reward, self.done\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningAgent:\n",
    "    def __init__(self, actions, alpha=0.2, gamma=0.95, epsilon=0.1):\n",
    "\n",
    "        #جدول Q لتخزين (state, action) -> Q-value\n",
    "        self.q_table = {}\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        #(مثلاً: [0,1,2,3])\n",
    "        self.actions = actions\n",
    "\n",
    "    def get_q_value(self, state, action):\n",
    "        return self.q_table.get((state, action), 0.0)\n",
    "\n",
    "    def choose_action(self, state, valid_actions):\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.choice(valid_actions)\n",
    "        q_vals = [self.get_q_value(state, a) for a in valid_actions]\n",
    "        max_q = max(q_vals)\n",
    "        best_actions = [a for a, q in zip(valid_actions, q_vals) if q == max_q]\n",
    "        return random.choice(best_actions)\n",
    "\n",
    "    def learn(self, state, action, reward, next_state, next_valid_actions):\n",
    "        current_q = self.get_q_value(state, action)\n",
    "        max_next_q = max([self.get_q_value(next_state, a) for a in next_valid_actions], default=0)\n",
    "        \n",
    "         # نحسب القيمة الجديدة باستخدام معادلة Q-Learning\n",
    "        new_q = current_q + self.alpha * (reward + self.gamma * max_next_q - current_q)\n",
    "        # update q-table\n",
    "        self.q_table[(state, action)] = new_q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done!\n",
      "Rewards per episode:  [335, 190, 345, 250, 245, 320, 225, 300, 210, 215, 210, 305, 195, 155, 245, 395, 215, 280, 295, 155, 235, 290, 285, 290, 365, 255, 220, 265, 110, 355, 165, 110, 280, 175, 380, 255, 200, 370, 130, 285, 210, 315, 245, 525, 165, 440, 290, 255, 125, 225]\n"
     ]
    }
   ],
   "source": [
    "#Function to gradually decrease epsilon with a minimum threshold of 0.01\n",
    "def update_epsilon(epsilon, decay_rate=0.9999):\n",
    "    return max(0.01, epsilon * decay_rate)\n",
    "\n",
    "\n",
    "env = LudoEnv()\n",
    "agent = QLearningAgent(actions=list(range(4))) # Initialize the Q-learning agent with 4 possible actions (representing the 4 pieces)\n",
    "\n",
    "\n",
    "episodes = 10000\n",
    "reward_per_episode = [] # List to store the total reward obtained in each episode\n",
    "\n",
    "import random\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()  # Reset the environment and get the initial state\n",
    "    total_reward = 0 # Initialize the total reward for this episode\n",
    "    while True:\n",
    "        valid_actions = env.get_valid_actions() # Get the list of valid actions for the current state\n",
    "        if not valid_actions:\n",
    "            break\n",
    "        action = agent.choose_action(state, valid_actions) # Let the agent choose an action (either explore or exploit)\n",
    "        next_state, reward, done = env.step(action) # Perform the action and get the next state, reward, and done flag\n",
    "        next_valid_actions = env.get_valid_actions() # Get the valid actions for the next state\n",
    "        agent.learn(state, action, reward, next_state, next_valid_actions) # Update the Q-table using the learning algorithm\n",
    "        state = next_state # Move to the next state\n",
    "        total_reward += reward # Accumulate the total reward for this episode\n",
    "\n",
    "        # If the game is finished ------> exit the loop\n",
    "        if done:\n",
    "            break\n",
    "    reward_per_episode.append(total_reward) # Store the total reward for this episode\n",
    "\n",
    "    # Gradually reduce the epsilon value to shift from exploration to exploitation\n",
    "    agent.epsilon = update_epsilon(agent.epsilon)\n",
    "\n",
    "\n",
    "print(\"Training done!\")\n",
    "print(\"Rewards per episode: \", reward_per_episode[:50])  # Display the total rewards for the first 50 episodes as a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
